{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 3: Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "This DAE machine learning architecture is inspired by the first place solution in Tabular Playground January by Danzel [1st place - turn your data into DAEta](https://www.kaggle.com/springmanndaniel/1st-place-turn-your-data-into-daeta/report). It is speculated that this works well since the data itself is artificially created with noise using CTGAN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fundamentals\n",
    "import six\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "# data exploration \n",
    "from pandas_profiling import ProfileReport\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=True, world_readable=True)\n",
    "from plotly.offline import iplot\n",
    "\n",
    "# data preprocessing \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, PowerTransformer, MinMaxScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# hyperparameter tuning \n",
    "import kerastuner as kt\n",
    "\n",
    "\n",
    "# metrics for evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "# saving parameters\n",
    "from joblib import dump, load\n",
    "\n",
    "# hyperparameter searching and tuning \n",
    "import optuna\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing random seed for reproducability\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('train.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = ['cat0','cat1','cat2','cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281421</td>\n",
       "      <td>0.881122</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.741413</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>0.724417</td>\n",
       "      <td>0.701915</td>\n",
       "      <td>0.877618</td>\n",
       "      <td>0.719903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.278495</td>\n",
       "      <td>0.593413</td>\n",
       "      <td>0.546056</td>\n",
       "      <td>0.613252</td>\n",
       "      <td>0.741289</td>\n",
       "      <td>0.326679</td>\n",
       "      <td>0.808464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293756</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.369602</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.865620</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.264104</td>\n",
       "      <td>0.695561</td>\n",
       "      <td>0.869133</td>\n",
       "      <td>0.828352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.934138</td>\n",
       "      <td>0.578930</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.868099</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>0.494269</td>\n",
       "      <td>0.698125</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.614766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279105</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.705940</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.462146</td>\n",
       "      <td>0.724447</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.343457</td>\n",
       "      <td>0.297743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499993</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768447</td>\n",
       "      <td>0.269578</td>\n",
       "      <td>0.258655</td>\n",
       "      <td>0.363598</td>\n",
       "      <td>0.300619</td>\n",
       "      <td>0.340516</td>\n",
       "      <td>0.235711</td>\n",
       "      <td>0.383477</td>\n",
       "      <td>0.215227</td>\n",
       "      <td>0.793630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775951</td>\n",
       "      <td>0.197211</td>\n",
       "      <td>0.257024</td>\n",
       "      <td>0.574304</td>\n",
       "      <td>0.227035</td>\n",
       "      <td>0.322583</td>\n",
       "      <td>0.286094</td>\n",
       "      <td>0.324874</td>\n",
       "      <td>0.306933</td>\n",
       "      <td>0.230902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297406</td>\n",
       "      <td>0.449482</td>\n",
       "      <td>0.386172</td>\n",
       "      <td>0.476217</td>\n",
       "      <td>0.135947</td>\n",
       "      <td>0.502730</td>\n",
       "      <td>0.235788</td>\n",
       "      <td>0.316671</td>\n",
       "      <td>0.250286</td>\n",
       "      <td>0.349041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758642</td>\n",
       "      <td>0.363130</td>\n",
       "      <td>0.324132</td>\n",
       "      <td>0.229017</td>\n",
       "      <td>0.220888</td>\n",
       "      <td>0.515304</td>\n",
       "      <td>0.389391</td>\n",
       "      <td>0.245234</td>\n",
       "      <td>0.303895</td>\n",
       "      <td>0.481138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696047</td>\n",
       "      <td>0.734712</td>\n",
       "      <td>0.404145</td>\n",
       "      <td>0.497719</td>\n",
       "      <td>0.497974</td>\n",
       "      <td>0.782585</td>\n",
       "      <td>0.751251</td>\n",
       "      <td>0.608412</td>\n",
       "      <td>0.712868</td>\n",
       "      <td>0.452400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont4  \\\n",
       "id                                                        ...             \n",
       "1         A    B    A    A    B    D    A    E    C    I  ...  0.281421   \n",
       "2         B    A    A    A    B    B    A    E    A    F  ...  0.282354   \n",
       "3         A    A    A    C    B    D    A    B    C    N  ...  0.293756   \n",
       "4         A    A    A    C    B    D    A    E    G    K  ...  0.769785   \n",
       "6         A    B    A    A    B    B    A    E    C    F  ...  0.279105   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "499993    A    B    A    C    B    B    A    E    E    L  ...  0.768447   \n",
       "499996    A    B    A    C    B    B    A    E    E    L  ...  0.775951   \n",
       "499997    A    B    A    C    B    B    A    E    C    M  ...  0.297406   \n",
       "499998    A    B    B    C    B    B    A    D    E    F  ...  0.758642   \n",
       "499999    A    A    B    A    B    D    A    E    C    K  ...  0.696047   \n",
       "\n",
       "           cont5     cont6     cont7     cont8     cont9    cont10    cont11  \\\n",
       "id                                                                             \n",
       "1       0.881122  0.421650  0.741413  0.895799  0.802461  0.724417  0.701915   \n",
       "2       0.440011  0.346230  0.278495  0.593413  0.546056  0.613252  0.741289   \n",
       "3       0.914155  0.369602  0.832564  0.865620  0.825251  0.264104  0.695561   \n",
       "4       0.934138  0.578930  0.407313  0.868099  0.794402  0.494269  0.698125   \n",
       "6       0.382600  0.705940  0.325193  0.440967  0.462146  0.724447  0.683073   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "499993  0.269578  0.258655  0.363598  0.300619  0.340516  0.235711  0.383477   \n",
       "499996  0.197211  0.257024  0.574304  0.227035  0.322583  0.286094  0.324874   \n",
       "499997  0.449482  0.386172  0.476217  0.135947  0.502730  0.235788  0.316671   \n",
       "499998  0.363130  0.324132  0.229017  0.220888  0.515304  0.389391  0.245234   \n",
       "499999  0.734712  0.404145  0.497719  0.497974  0.782585  0.751251  0.608412   \n",
       "\n",
       "          cont12    cont13  \n",
       "id                          \n",
       "1       0.877618  0.719903  \n",
       "2       0.326679  0.808464  \n",
       "3       0.869133  0.828352  \n",
       "4       0.809799  0.614766  \n",
       "6       0.343457  0.297743  \n",
       "...          ...       ...  \n",
       "499993  0.215227  0.793630  \n",
       "499996  0.306933  0.230902  \n",
       "499997  0.250286  0.349041  \n",
       "499998  0.303895  0.481138  \n",
       "499999  0.712868  0.452400  \n",
       "\n",
       "[300000 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = original_df.drop(columns = 'target', axis =1)\n",
    "Y_train = original_df['target']\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.concat([X_train, test], axis = 0)\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "# passing max 4 cardinality category column (label encoded values of bridge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.fit(X_train[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5']])\n",
    "enc_df = pd.DataFrame(enc.transform(X_train[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5']]).toarray())\n",
    "enc_df.index = X_train.index\n",
    "# merge with main df with encoded df on key values\n",
    "X_train = pd.concat([X_train, enc_df], ignore_index = False, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df = pd.DataFrame(enc.transform(test[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5']]).toarray())\n",
    "enc_df.index = test.index\n",
    "# merge with main df with encoded df on key values\n",
    "test = pd.concat([test, enc_df], ignore_index = False, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df = pd.DataFrame(enc.transform(input_data[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5']]).toarray())\n",
    "enc_df.index = input_data.index\n",
    "# merge with main df with encoded df on key values\n",
    "input_data = pd.concat([input_data, enc_df], ignore_index = False, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499987</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...    8    9   10  \\\n",
       "id                                                        ...                  \n",
       "1         A    B    A    A    B    D    A    E    C    I  ...  0.0  0.0  0.0   \n",
       "2         B    A    A    A    B    B    A    E    A    F  ...  0.0  0.0  0.0   \n",
       "3         A    A    A    C    B    D    A    B    C    N  ...  1.0  0.0  0.0   \n",
       "4         A    A    A    C    B    D    A    E    G    K  ...  1.0  0.0  0.0   \n",
       "6         A    B    A    A    B    B    A    E    C    F  ...  0.0  0.0  0.0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "499987    A    A    A    C    B    D    A    E    G    L  ...  1.0  0.0  0.0   \n",
       "499990    A    A    A    C    B    D    A    E    E    F  ...  1.0  0.0  0.0   \n",
       "499991    A    A    A    C    B    D    A    E    C    K  ...  1.0  0.0  0.0   \n",
       "499994    A    B    A    A    B    D    A    E    C    F  ...  0.0  0.0  0.0   \n",
       "499995    A    B    A    C    B    C    A    E    G    H  ...  1.0  0.0  0.0   \n",
       "\n",
       "         11   12   13   14   15   16   17  \n",
       "id                                         \n",
       "1       1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "2       1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3       1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4       1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "6       1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "499987  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "499990  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "499991  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "499994  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "499995  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[500000 rows x 42 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cont0</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>0.923191</td>\n",
       "      <td>0.684968</td>\n",
       "      <td>0.124454</td>\n",
       "      <td>0.217886</td>\n",
       "      <td>0.281421</td>\n",
       "      <td>0.881122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0.437627</td>\n",
       "      <td>0.014213</td>\n",
       "      <td>0.357438</td>\n",
       "      <td>0.846127</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>0.732209</td>\n",
       "      <td>0.760122</td>\n",
       "      <td>0.454644</td>\n",
       "      <td>0.812990</td>\n",
       "      <td>0.293756</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>K</td>\n",
       "      <td>0.705142</td>\n",
       "      <td>0.771678</td>\n",
       "      <td>0.153735</td>\n",
       "      <td>0.732893</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.934138</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>0.486063</td>\n",
       "      <td>0.639349</td>\n",
       "      <td>0.496212</td>\n",
       "      <td>0.354186</td>\n",
       "      <td>0.279105</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499987</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>L</td>\n",
       "      <td>0.919265</td>\n",
       "      <td>0.111147</td>\n",
       "      <td>0.199583</td>\n",
       "      <td>0.181354</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.963678</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>0.362875</td>\n",
       "      <td>-0.020197</td>\n",
       "      <td>0.469025</td>\n",
       "      <td>0.336185</td>\n",
       "      <td>0.523174</td>\n",
       "      <td>0.232072</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>0.463060</td>\n",
       "      <td>0.740421</td>\n",
       "      <td>0.446293</td>\n",
       "      <td>0.411387</td>\n",
       "      <td>0.517103</td>\n",
       "      <td>0.432927</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>0.708709</td>\n",
       "      <td>0.418490</td>\n",
       "      <td>0.193004</td>\n",
       "      <td>0.862700</td>\n",
       "      <td>0.279153</td>\n",
       "      <td>0.837712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>0.646432</td>\n",
       "      <td>0.484954</td>\n",
       "      <td>0.141289</td>\n",
       "      <td>0.753487</td>\n",
       "      <td>0.763246</td>\n",
       "      <td>0.792263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat6 cat7 cat8 cat9     cont0     cont1     cont2     cont3     cont4  \\\n",
       "id                                                                             \n",
       "1         A    E    C    I  0.923191  0.684968  0.124454  0.217886  0.281421   \n",
       "2         A    E    A    F  0.437627  0.014213  0.357438  0.846127  0.282354   \n",
       "3         A    B    C    N  0.732209  0.760122  0.454644  0.812990  0.293756   \n",
       "4         A    E    G    K  0.705142  0.771678  0.153735  0.732893  0.769785   \n",
       "6         A    E    C    F  0.486063  0.639349  0.496212  0.354186  0.279105   \n",
       "...     ...  ...  ...  ...       ...       ...       ...       ...       ...   \n",
       "499987    A    E    G    L  0.919265  0.111147  0.199583  0.181354  0.277365   \n",
       "499990    A    E    E    F  0.362875 -0.020197  0.469025  0.336185  0.523174   \n",
       "499991    A    E    C    K  0.463060  0.740421  0.446293  0.411387  0.517103   \n",
       "499994    A    E    C    F  0.708709  0.418490  0.193004  0.862700  0.279153   \n",
       "499995    A    E    G    H  0.646432  0.484954  0.141289  0.753487  0.763246   \n",
       "\n",
       "           cont5  ...    8    9   10   11   12   13   14   15   16   17  \n",
       "id                ...                                                    \n",
       "1       0.881122  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "2       0.440011  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "3       0.914155  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "4       0.934138  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "6       0.382600  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "...          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "499987  0.963678  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "499990  0.232072  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "499991  0.432927  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "499994  0.837712  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "499995  0.792263  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[500000 rows x 36 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in [X_train, test, input_data]:\n",
    "    df.drop(columns = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5'], inplace = True)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = OrdinalEncoder()\n",
    "le.fit(X_train[['cat6', 'cat7', 'cat8','cat9']])\n",
    "X_train[['cat6', 'cat7', 'cat8','cat9']] = le.transform(X_train[['cat6', 'cat7', 'cat8','cat9']])\n",
    "test[['cat6', 'cat7', 'cat8','cat9']] = le.transform(test[['cat6', 'cat7', 'cat8','cat9']])\n",
    "input_data[['cat6', 'cat7', 'cat8','cat9']] = le.transform(input_data[['cat6', 'cat7', 'cat8','cat9']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cont0</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>...</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.923191</td>\n",
       "      <td>0.684968</td>\n",
       "      <td>0.124454</td>\n",
       "      <td>0.217886</td>\n",
       "      <td>0.281421</td>\n",
       "      <td>0.881122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.437627</td>\n",
       "      <td>0.014213</td>\n",
       "      <td>0.357438</td>\n",
       "      <td>0.846127</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.732209</td>\n",
       "      <td>0.760122</td>\n",
       "      <td>0.454644</td>\n",
       "      <td>0.812990</td>\n",
       "      <td>0.293756</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.705142</td>\n",
       "      <td>0.771678</td>\n",
       "      <td>0.153735</td>\n",
       "      <td>0.732893</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.934138</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.486063</td>\n",
       "      <td>0.639349</td>\n",
       "      <td>0.496212</td>\n",
       "      <td>0.354186</td>\n",
       "      <td>0.279105</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.919265</td>\n",
       "      <td>0.111147</td>\n",
       "      <td>0.199583</td>\n",
       "      <td>0.181354</td>\n",
       "      <td>0.277365</td>\n",
       "      <td>0.963678</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.362875</td>\n",
       "      <td>-0.020197</td>\n",
       "      <td>0.469025</td>\n",
       "      <td>0.336185</td>\n",
       "      <td>0.523174</td>\n",
       "      <td>0.232072</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.463060</td>\n",
       "      <td>0.740421</td>\n",
       "      <td>0.446293</td>\n",
       "      <td>0.411387</td>\n",
       "      <td>0.517103</td>\n",
       "      <td>0.432927</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.708709</td>\n",
       "      <td>0.418490</td>\n",
       "      <td>0.193004</td>\n",
       "      <td>0.862700</td>\n",
       "      <td>0.279153</td>\n",
       "      <td>0.837712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.646432</td>\n",
       "      <td>0.484954</td>\n",
       "      <td>0.141289</td>\n",
       "      <td>0.753487</td>\n",
       "      <td>0.763246</td>\n",
       "      <td>0.792263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat6  cat7  cat8  cat9     cont0     cont1     cont2     cont3  \\\n",
       "id                                                                       \n",
       "1        0.0   4.0   2.0   8.0  0.923191  0.684968  0.124454  0.217886   \n",
       "2        0.0   4.0   0.0   5.0  0.437627  0.014213  0.357438  0.846127   \n",
       "3        0.0   1.0   2.0  13.0  0.732209  0.760122  0.454644  0.812990   \n",
       "4        0.0   4.0   6.0  10.0  0.705142  0.771678  0.153735  0.732893   \n",
       "6        0.0   4.0   2.0   5.0  0.486063  0.639349  0.496212  0.354186   \n",
       "...      ...   ...   ...   ...       ...       ...       ...       ...   \n",
       "499987   0.0   4.0   6.0  11.0  0.919265  0.111147  0.199583  0.181354   \n",
       "499990   0.0   4.0   4.0   5.0  0.362875 -0.020197  0.469025  0.336185   \n",
       "499991   0.0   4.0   2.0  10.0  0.463060  0.740421  0.446293  0.411387   \n",
       "499994   0.0   4.0   2.0   5.0  0.708709  0.418490  0.193004  0.862700   \n",
       "499995   0.0   4.0   6.0   7.0  0.646432  0.484954  0.141289  0.753487   \n",
       "\n",
       "           cont4     cont5  ...    8    9   10   11   12   13   14   15   16  \\\n",
       "id                          ...                                                \n",
       "1       0.281421  0.881122  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2       0.282354  0.440011  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "3       0.293756  0.914155  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4       0.769785  0.934138  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "6       0.279105  0.382600  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
       "...          ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "499987  0.277365  0.963678  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "499990  0.523174  0.232072  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "499991  0.517103  0.432927  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "499994  0.279153  0.837712  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
       "499995  0.763246  0.792263  ...  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "         17  \n",
       "id           \n",
       "1       1.0  \n",
       "2       0.0  \n",
       "3       1.0  \n",
       "4       1.0  \n",
       "6       0.0  \n",
       "...     ...  \n",
       "499987  1.0  \n",
       "499990  1.0  \n",
       "499991  1.0  \n",
       "499994  1.0  \n",
       "499995  0.0  \n",
       "\n",
       "[500000 rows x 36 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = len(input_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "test = scaler.transform(test)\n",
    "input_data = scaler.transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputSwapNoiseTEST(arr, p, randomise_type = 'random'):\n",
    "    '''\n",
    "    Takes a numpy array and swaps a row of each \n",
    "    feature with another value from the same column with probability p\n",
    "    '''\n",
    "\n",
    "    n, m = arr.shape #row, col\n",
    "    idx = range(n)\n",
    "    swap_n = round(n*p)\n",
    "    arr2 = arr.copy()\n",
    "\n",
    "    if randomise_type == 'random':\n",
    "        for i in range(m):\n",
    "            col_vals = np.random.permutation(arr[:, i]) \n",
    "            swap_idx = np.random.choice(idx, size= swap_n) \n",
    "            arr2[swap_idx, i] = np.random.choice(col_vals, size = swap_n) # n*p row and change it \n",
    "            \n",
    "    elif randomise_type == 'row':\n",
    "        row_ref = np.random.permutation(n) # change the order of the row\n",
    "        for i in range(m):\n",
    "            swap_idx = np.random.choice(idx, size= swap_n) # choose row\n",
    "            arr2[swap_idx,i] = np.random.choice(col_vals, size = swap_n) # n*p row and change it \n",
    "            \n",
    "    return arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10],\n",
       "       [11, 12, 13, 14, 15],\n",
       "       [16, 17, 18, 19, 20],\n",
       "       [21, 22, 23, 24, 25],\n",
       "       [26, 27, 28, 29, 30]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.arange(1,31).reshape(6,5)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10],\n",
       "       [11, 12, 13, 14, 20],\n",
       "       [16, 17, 18, 19, 20],\n",
       "       [21,  2,  3, 24, 25],\n",
       "       [26, 27, 28, 29, 30]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2 =  inputSwapNoiseTEST(matrix, p = 0.2, randomise_type = 'random')\n",
    "matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 36)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldAverageDAE:\n",
    "    def __init__(self, FOLDS):\n",
    "        # creating CV folds for training \n",
    "        self.models = []\n",
    "        self.kfolds = KFold(n_splits = FOLDS, \n",
    "                            shuffle = True,\n",
    "                            random_state = 50)\n",
    "        \n",
    "        \n",
    "    def get_autoencoder_model(self, train_x):\n",
    "        \"\"\"\n",
    "        transform the 1 row of 36 features (1 * 36) into (3 * 800) layers autoencoder\n",
    "        \n",
    "        \"\"\"\n",
    "        len_input_output = train_x.shape[-1]\n",
    "        self.input_ = keras.Input((len_input_output,), name = 'original_data')\n",
    "        self.encode1 = Dense(units = 4096, activation='relu')(self.input_)\n",
    "        self.encode2 = Dense(units = 1024, activation='relu')(self.encode1)\n",
    "        self.encode3 = Dense(units = 1024, activation='relu')(self.encode2)\n",
    "        self.encode4 = Dense(units = 512, activation='relu')(self.encode3)\n",
    "        self.deepstack1 = Dense(units=16, activation='relu')(self.encode4)\n",
    "        self.deepstack2 = Dense(units=16, activation='relu')(self.deepstack1)\n",
    "        self.deepstack3 = Dense(units=16, activation='relu')(self.deepstack2)\n",
    "        \n",
    "        # Use only the encoder part for denoising \n",
    "        self.encoder = keras.Model(inputs= self.input_, outputs=[self.deepstack1,\n",
    "                                                            self.deepstack2, \n",
    "                                                            self.deepstack3], name = \"encoder\")   \n",
    "        self.encoder.summary()\n",
    "        \n",
    "        \n",
    "        self.decoder_input = keras.Input(shape = (16,), name = 'encoded_data')\n",
    "        self.decoder1 = Dense(units = 512, activation='relu')(self.decoder_input)\n",
    "        self.decoder2 = Dense(units = 1024, activation='relu')(self.decoder1)\n",
    "        self.decoder3 = Dense(units = 1024, activation='relu')(self.decoder2)\n",
    "        self.decoder4 = Dense(units=4096, activation='relu')(self.decoder3)\n",
    "        self.decoder_output = Dense(units = len_input_output, activation = 'linear')(self.decoder4)\n",
    "        self.decoder = keras.Model(self.decoder_input, self.decoder_output, name = \"decoders\")\n",
    "        self.decoder.summary()\n",
    "        \n",
    "        # Training is performed on the entire autoencoder\n",
    "        \n",
    "        self.autoencoder_input = keras.Input((len_input_output,), name = 'data')\n",
    "        self.encoded_data = self.encoder(self.autoencoder_input)\n",
    "        self.decoded_data = self.decoder(self.encoded_data[2]) #i.e. DS layer 3\n",
    "        self.autoencoder = keras.Model(inputs = self.autoencoder_input, \n",
    "                                       outputs= self.decoded_data,\n",
    "                                      name = \"autoencoder\")\n",
    "        \n",
    "        \n",
    "        self.autoencoder.summary()\n",
    "        \n",
    "        self.autoencoder.compile(optimizer = Adam(learning_rate = 0.1), loss = 'mse', metrics = 'mse')\n",
    "        \n",
    "        model = self\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def inputSwapNoise(self, arr, p, randomise_type = 'random'):\n",
    "        '''\n",
    "        Takes a numpy array and swaps a row of each \n",
    "        feature with another value from the same column with probability p\n",
    "        '''\n",
    "\n",
    "        n, m = arr.shape\n",
    "        idx = range(n)\n",
    "        swap_n = round(n*p)\n",
    "        arr2 = arr.copy()\n",
    "        for i in range(m):\n",
    "            col_vals = np.random.permutation(arr[:, i]) # change the order of the row\n",
    "            swap_idx = np.random.choice(idx, size= swap_n) # choose row\n",
    "            arr2[swap_idx, i] = np.random.choice(col_vals, size = swap_n) # n*p row and change it \n",
    "        return arr2\n",
    "        \n",
    "    def autoencoder_fit(self, INPUT_DATA, BATCH_SIZE, EPOCHS, p, randomise_type = 'random'):\n",
    "        \n",
    "        noised_data = self.inputSwapNoise(INPUT_DATA, p)\n",
    "\n",
    "        oof_preds = np.zeros_like(INPUT_DATA)\n",
    "        self.noised_data = pd.DataFrame(noised_data).values\n",
    "        self.INPUT_DATA = pd.DataFrame(INPUT_DATA).values\n",
    "        \n",
    "        \n",
    "        # adding callbacks\n",
    "        model_save = ModelCheckpoint('./best_DAE_model.h5', \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = True,\n",
    "                             monitor = 'val_loss', \n",
    "                             mode = 'min', verbose = 10)\n",
    "        early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.0005, \n",
    "                           patience = 10, mode = 'min', verbose = 10,\n",
    "                           restore_best_weights = True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, \n",
    "                              patience = 5, min_delta = 0.0005, \n",
    "                              mode = 'min', verbose = 10)\n",
    "        \n",
    "        \n",
    "        for train_idx, val_idx in self.kfolds.split(INPUT_DATA):\n",
    "            noised_data_train_CV, noised_data_val_CV = self.noised_data[train_idx], self.noised_data[val_idx]\n",
    "            INPUT_DATA_train_CV, INPUT_DATA_val_CV = self.INPUT_DATA[train_idx], self.INPUT_DATA[val_idx]\n",
    "            \n",
    "                \n",
    "            model.autoencoder.fit(x = noised_data_train_CV, \n",
    "                                      y = INPUT_DATA_train_CV, \n",
    "                                      batch_size = BATCH_SIZE,\n",
    "                                      validation_data = (noised_data_val_CV,INPUT_DATA_val_CV),\n",
    "                                      epochs = EPOCHS, \n",
    "                                      callbacks = [model_save, early_stop, reduce_lr])\n",
    "            \n",
    "            \n",
    "            self.models.append(model)\n",
    "            oof_pred = self.autoencoder.predict(noised_data_val_CV)\n",
    "            oof_preds[val_idx] = oof_pred\n",
    "\n",
    "        self.oof_preds = oof_preds\n",
    "        \n",
    "        self.rmse = mean_squared_error(INPUT_DATA, oof_preds, squared = False)\n",
    "        \n",
    "    def encoder_predict(self, test_x):\n",
    "        preds = []\n",
    "        for model in tqdm.tqdm(self.models):\n",
    "            pred = model.encoder.predict(test_x)\n",
    "            preds.append(pred)\n",
    "        preds = np.mean(preds, axis=0)\n",
    "        return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.57142857, 0.33333333, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.57142857, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.14285714, 0.33333333, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.        , 0.57142857, 0.33333333, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.42857143, 0.66666667, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.57142857, 0.33333333, ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KFoldAverageDAE(FOLDS = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "original_data (InputLayer)   [(None, 36)]              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4096)              151552    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 16)                272       \n",
      "=================================================================\n",
      "Total params: 5,930,032\n",
      "Trainable params: 5,930,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoders\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoded_data (InputLayer)    [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               8704      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 36)                147492    \n",
      "=================================================================\n",
      "Total params: 5,929,508\n",
      "Trainable params: 5,929,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (InputLayer)            [(None, 36)]              0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 16), (None, 16),  5930032   \n",
      "_________________________________________________________________\n",
      "decoders (Functional)        (None, 36)                5929508   \n",
      "=================================================================\n",
      "Total params: 11,859,540\n",
      "Trainable params: 11,859,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model.get_autoencoder_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model.encoder, \"encoder.png\", show_shapes=True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model.decoder, \"decoder.png\", show_shapes=True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model.autoencoder, \"DAE.png\", show_shapes=True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 368614771548486.6875 - mse: 368614771548486.6875 - val_loss: 0.1070 - val_mse: 0.1070\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10702, saving model to .\\best_DAE_model.h5\n",
      "Epoch 2/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 2356.4233 - mse: 2356.4233 - val_loss: 0.0776 - val_mse: 0.0776\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10702 to 0.07763, saving model to .\\best_DAE_model.h5\n",
      "Epoch 3/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07763 to 0.07645, saving model to .\\best_DAE_model.h5\n",
      "Epoch 4/1000\n",
      "25000/25000 [==============================] - 175s 7ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0770 - val_mse: 0.0770\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07645\n",
      "Epoch 5/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0777 - val_mse: 0.0777\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07645\n",
      "Epoch 6/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0782 - val_mse: 0.0782\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07645\n",
      "Epoch 7/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0781 - mse: 0.0781 - val_loss: 0.0792 - val_mse: 0.0792\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07645\n",
      "Epoch 8/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0782 - mse: 0.0782 - val_loss: 0.0783 - val_mse: 0.0783\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07645\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 9/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07645 to 0.07568, saving model to .\\best_DAE_model.h5\n",
      "Epoch 10/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07568\n",
      "Epoch 11/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0759 - mse: 0.0759 - val_loss: 0.0757 - val_mse: 0.0757\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07568 to 0.07567, saving model to .\\best_DAE_model.h5\n",
      "Epoch 12/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0760 - mse: 0.0760 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.07567\n",
      "Epoch 13/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0760 - mse: 0.0760 - val_loss: 0.0759 - val_mse: 0.0759\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.07567\n",
      "Epoch 14/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0760 - mse: 0.0760 - val_loss: 0.0758 - val_mse: 0.0758\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.07567\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 15/1000\n",
      "25000/25000 [==============================] - 175s 7ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07567 to 0.07549, saving model to .\\best_DAE_model.h5\n",
      "Epoch 16/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.07549\n",
      "Epoch 17/1000\n",
      "25000/25000 [==============================] - 175s 7ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07549\n",
      "Epoch 18/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07549\n",
      "Epoch 19/1000\n",
      "25000/25000 [==============================] - 175s 7ms/step - loss: 0.0757 - mse: 0.0757 - val_loss: 0.0755 - val_mse: 0.0755\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07549\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 00019: early stopping\n",
      "Epoch 1/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.07549\n",
      "Epoch 2/1000\n",
      "25000/25000 [==============================] - 176s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07549\n",
      "Epoch 3/1000\n",
      "25000/25000 [==============================] - 176s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07549\n",
      "Epoch 4/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07549\n",
      "Epoch 5/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07549\n",
      "Epoch 6/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07549\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 7/1000\n",
      "25000/25000 [==============================] - 174s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07549\n",
      "Epoch 8/1000\n",
      "25000/25000 [==============================] - 175s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07549\n",
      "Epoch 9/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07549\n",
      "Epoch 10/1000\n",
      "25000/25000 [==============================] - 177s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07549\n",
      "Epoch 11/1000\n",
      "25000/25000 [==============================] - 175s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.07549\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.07549\n",
      "Epoch 2/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.07549\n",
      "Epoch 3/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07549\n",
      "Epoch 4/1000\n",
      "25000/25000 [==============================] - 172s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07549\n",
      "Epoch 5/1000\n",
      "25000/25000 [==============================] - 173s 7ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07549\n",
      "Epoch 6/1000\n",
      "25000/25000 [==============================] - 202s 8ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07549\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 7/1000\n",
      "25000/25000 [==============================] - 234s 9ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07549\n",
      "Epoch 8/1000\n",
      "25000/25000 [==============================] - 223s 9ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07549\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 236s 9ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.07549\n",
      "Epoch 10/1000\n",
      "25000/25000 [==============================] - 241s 10ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.07549\n",
      "Epoch 11/1000\n",
      "25000/25000 [==============================] - 229s 9ms/step - loss: 0.0756 - mse: 0.0756 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.07549\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/1000\n",
      " 2487/25000 [=>............................] - ETA: 3:11 - loss: 0.0758 - mse: 0.0758"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f2d6cd6ffb5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                       \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                       \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                       p = 0.3)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-4688ec710f79>\u001b[0m in \u001b[0;36mautoencoder_fit\u001b[1;34m(self, INPUT_DATA, BATCH_SIZE, EPOCHS, p, randomise_type)\u001b[0m\n\u001b[0;32m    106\u001b[0m                                       \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnoised_data_val_CV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mINPUT_DATA_val_CV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                                       \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                                       callbacks = [model_save, early_stop, reduce_lr])\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.autoencoder_fit(input_data, \n",
    "                      BATCH_SIZE = 16, \n",
    "                      EPOCHS = 1000,\n",
    "                      p = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:41<00:00,  8.37s/it]\n"
     ]
    }
   ],
   "source": [
    "encoded_X_train = model.encoder_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoded_X_train.joblib']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(encoded_X_train, \"encoded_X_train.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:30<00:00,  6.02s/it]\n"
     ]
    }
   ],
   "source": [
    "encoded_X_test = model.encoder_predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoded_X_test.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(encoded_X_test, \"encoded_X_test.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12009786, 0.12640166, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.44631195, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.21731094, 0.4441418 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1147465 ,\n",
       "       0.27347428, 0.        , 0.        , 0.36857966, 0.        ,\n",
       "       0.05280513, 0.36706027, 0.        , 0.37698156, 0.        ,\n",
       "       0.        , 0.        , 0.08929306, 0.1660731 , 0.        ,\n",
       "       0.        , 0.15715303, 0.3208198 , 0.        , 0.        ,\n",
       "       0.1448954 , 0.20213398, 0.5857546 , 0.14967312, 0.        ,\n",
       "       0.22405055, 0.        , 0.34649685, 0.5353485 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.48480624, 0.17144634, 0.23440376,\n",
       "       0.2678754 , 0.5993608 , 0.        , 0.01253927, 0.22427464,\n",
       "       0.        , 0.1107884 , 0.        , 0.        , 0.2952196 ,\n",
       "       0.        , 0.22177884, 0.        , 0.22270393, 0.28120175,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.36129546,\n",
       "       0.25969753, 0.09154522, 0.15598956, 0.        , 0.        ,\n",
       "       0.        , 0.2241052 , 0.        , 0.        , 0.13318375,\n",
       "       0.        , 0.44152647, 0.        , 0.        , 0.        ,\n",
       "       0.18175687, 0.19059871, 0.45567626, 0.        , 0.5305491 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.16770424, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.23550186, 0.        , 0.10059728, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.2179561 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3830049 , 0.        , 0.        ,\n",
       "       0.27061126, 0.02715881, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.58449876, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.23600909, 0.        , 0.33796668, 0.        ,\n",
       "       0.        , 0.72547835, 0.        , 0.72666705, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.2822798 ,\n",
       "       0.        , 0.        , 0.27690312, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.10973506,\n",
       "       0.44301122, 0.        , 0.        , 0.16510376, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.5159579 , 0.10633372, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3039891 , 0.        , 0.        ,\n",
       "       0.05502365, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.24949047, 0.        , 0.        , 0.19425167, 0.        ,\n",
       "       0.        , 0.24322173, 0.21855035, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.31508783,\n",
       "       0.        , 0.        , 0.20271626, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19645943, 0.        ,\n",
       "       0.09621526, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.6113442 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.19425967,\n",
       "       0.        , 0.13149202, 0.        , 0.        , 0.24263188,\n",
       "       0.08870883, 0.        , 0.        , 0.        , 0.3877029 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26994723, 0.        , 0.        ,\n",
       "       0.24982461, 0.351472  , 0.        , 0.7919445 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07246547, 0.        , 0.1033424 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.40324312,\n",
       "       0.        , 0.229074  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.44568175,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.29336712, 0.        , 0.        , 0.        , 0.25933462,\n",
       "       0.        , 0.        , 0.35524958, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.37563208,\n",
       "       0.        , 0.        , 0.4209407 , 0.        , 0.        ,\n",
       "       0.        , 0.21283033, 0.20310047, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.1051756 , 0.        ,\n",
       "       0.        , 0.        , 0.3962209 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23949674, 0.35678297, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.348291  , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.13017787, 0.        , 0.39090624, 0.37097958, 0.32473773,\n",
       "       0.3636572 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.16707751, 0.        , 0.        , 0.43297523, 0.        ,\n",
       "       0.        , 0.        , 0.18739508, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.37651134, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.12151376,\n",
       "       0.        , 0.        , 0.        , 0.43353313, 0.24804696,\n",
       "       0.        , 0.30759665, 0.        , 0.        , 0.07881939,\n",
       "       0.        , 0.        , 0.        , 0.23548868, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.29246637, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.33948845, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.24864101, 0.3155122 , 0.        , 0.        , 0.        ,\n",
       "       0.4794255 , 0.        , 0.        , 0.        , 0.15477921,\n",
       "       0.        , 0.        , 0.18606743, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.10363199, 0.        ,\n",
       "       0.        , 0.        , 0.33174047, 0.12772897, 0.39009526,\n",
       "       0.        , 0.09227075, 0.35578132, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3328569 , 0.10432659, 0.11288024,\n",
       "       0.        , 0.37344036, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.34872466,\n",
       "       0.3274348 , 0.        , 0.38819128, 0.        , 0.        ,\n",
       "       0.        , 0.34571576, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32951593, 0.        , 0.        ,\n",
       "       0.        , 0.04946512, 0.314826  , 0.        , 0.2902245 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    for i in range(hp.Int('num_layers', 2,20)):\n",
    "        model.add(Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_' + str(i),\n",
    "                                            min_value=0,\n",
    "                                            max_value=0.4,\n",
    "                                            step=0.001)))\n",
    "        \n",
    "    model.add(Dense(units=1, activation = 'linear'))\n",
    "    # Tune the learning rate for the optimizer \n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [0.999, 1e-1, 5e-2, 1e-2, 1e-3]) \n",
    "    model.compile(optimizer = Adam(learning_rate = hp_learning_rate),\n",
    "                loss = 'mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import KerasPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "            model_builder,\n",
    "            objective='loss',\n",
    "            max_epochs=400,\n",
    "            hyperband_iterations = 2,\n",
    "            factor = 2,\n",
    "            overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "num_layers        |4                 |?                 \n",
      "units_0           |416               |?                 \n",
      "dropout_0         |0.133             |?                 \n",
      "units_1           |128               |?                 \n",
      "dropout_1         |0.058             |?                 \n",
      "learning_rate     |0.05              |?                 \n",
      "tuner/epochs      |2                 |?                 \n",
      "tuner/initial_e...|0                 |?                 \n",
      "tuner/bracket     |8                 |?                 \n",
      "tuner/round       |0                 |?                 \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 300000\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-e10cb0a4f53d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m tuner.search(encoded_X_train, \n\u001b[0;32m      2\u001b[0m              \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m              epochs = 40)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\kerastuner\\tuners\\hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tuner/epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'initial_epoch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tuner/initial_epoch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m    140\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1527\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[0;32m   1528\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1529\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 300000\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "tuner.search(encoded_X_train, \n",
    "             Y_train, \n",
    "             epochs = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(Y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldsAverageMLP():\n",
    "    def __init__(self, FOLDS):\n",
    "        self.models = []\n",
    "        self.kfolds = KFold(n_splits = FOLDS, shuffle = False)\n",
    "        \n",
    "    def fit(self, trial, train_x, train_y, prune = True):\n",
    "        oof_preds = np.zeros_like(train_y)\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y.values\n",
    "\n",
    "        \n",
    "        \n",
    "        # adding callbacks\n",
    "        model_save = ModelCheckpoint('./best_MLP_model.h5', \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = True,\n",
    "                             monitor = 'val_loss', \n",
    "                             mode = 'min', verbose = 10)\n",
    "        early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n",
    "                           patience = 5, mode = 'min', verbose = 10,\n",
    "                           restore_best_weights = True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, \n",
    "                              patience = 3, min_delta = 0.001, \n",
    "                              mode = 'min', verbose = 10)\n",
    "        \n",
    "        ###############################################################\n",
    "        stack_num, num_data, encoded_features = self.train_x.shape\n",
    "        \n",
    "        # tunable hyperparameters\n",
    "        input_dense = int(trial.suggest_loguniform('input_dense_layer', 16, 1024))\n",
    "        input_dropout = trial.suggest_loguniform('input_dropout', 1e-10, 1)\n",
    "        num_layers =  trial.suggest_int('num_layers', 10, 40)\n",
    "        learning_rate = trial.suggest_categorical('learning_rate', [0.999, 1e-1, 5e-2, 1e-2, 1e-3])\n",
    "        \n",
    "        combined_dense = int(trial.suggest_loguniform('combined_dense_layer', 16, 1024))\n",
    "        combined_dropout = trial.suggest_loguniform('combined_dropout', 1e-10, 1)\n",
    "                    \n",
    "        # the 3 deepstack layers would go through a mini-model before concat to combined NN\n",
    "        input_a = keras.Input(shape = (encoded_features,), name = 'deepstack layer 1 input')\n",
    "        x = Dense(input_dense, activation = 'relu')(input_a)\n",
    "        x = Dropout(input_dropout)(x)\n",
    "        model_a = keras.Model(input_a, x, name = 'stack_1')\n",
    "        \n",
    "        input_b = keras.Input(shape = (encoded_features,), name = 'deepstack layer 2 input')\n",
    "        y = Dense(input_dense, activation = 'relu')(input_b)\n",
    "        y = Dropout(input_dropout)(y)\n",
    "        model_b = keras.Model(input_b,  y, name = 'stack_2')\n",
    "        \n",
    "        \n",
    "        input_c = keras.Input(shape = (encoded_features,), name = 'deepstack layer 3 input')\n",
    "        z = Dense(input_dense, activation = 'relu')(input_c)\n",
    "        z = Dropout(input_dropout)(z)\n",
    "        model_c = keras.Model(input_c,  z, name = 'stack_3')\n",
    "        \n",
    "        # the output from the three mini models \n",
    "        merged = keras.layers.Concatenate(axis=1)([x, y, z])\n",
    "        combined = Dense(combined_dense, activation = 'relu', name = 'combining_dense')(merged)\n",
    "        piped_data = Dropout(combined_dropout)(combined)\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            num_hidden = int(trial.suggest_loguniform(f'n_units_l{i}', 32, 1024))\n",
    "            dropout_rate = trial.suggest_loguniform(f'dropout_rate{i}', 1e-10, 1)\n",
    "            piped_data = Dense(num_hidden, activation='relu')(piped_data)\n",
    "            piped_data = Dropout(rate=dropout_rate)(piped_data)\n",
    "\n",
    "        output = Dense(units=1, activation = 'linear')(piped_data)\n",
    "        MLP = keras.Model([input_a, input_b, input_c], output)\n",
    "        \n",
    "        # Tune the learning rate for the optimizer \n",
    "        # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "        MLP.compile(optimizer = Adam(learning_rate = learning_rate), loss = 'mse', metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "        \n",
    "        for train_idx, val_idx in self.kfolds.split(train_x[0]):\n",
    "            \n",
    "            \n",
    "            # spliting the three deepstack layers into different input models before combining \n",
    "            X_train_CV0, X_val_CV0 = self.train_x[0][train_idx], self.train_x[0][val_idx]\n",
    "            X_train_CV1, X_val_CV1 = self.train_x[1][train_idx], self.train_x[1][val_idx]\n",
    "            X_train_CV2, X_val_CV2 = self.train_x[2][train_idx], self.train_x[2][val_idx]\n",
    "            \n",
    "            Y_train_CV, Y_val_CV = self.train_y[train_idx], self.train_y[val_idx]\n",
    "            \n",
    "            MLP.fit(x = [X_train_CV0, X_train_CV1, X_train_CV2], \n",
    "                      y = Y_train_CV, \n",
    "                      epochs = 1000,\n",
    "                      verbose = 1, \n",
    "                      validation_data = ([X_val_CV0, X_val_CV1, X_val_CV2] , Y_val_CV),\n",
    "                      callbacks = [early_stop,\n",
    "                                    reduce_lr])       \n",
    "        \n",
    "            self.models.append(MLP)\n",
    "            oof_pred = MLP.predict([X_val_CV0, X_val_CV1, X_val_CV2])\n",
    "            oof_preds[val_idx] = oof_pred[0]\n",
    "            \n",
    "        self.oof_preds = oof_preds\n",
    "        \n",
    "        self.rmse = mean_squared_error(Y_train, oof_preds, squared = False)\n",
    "\n",
    "    def predict(self, test_x):\n",
    "        preds = []\n",
    "        for model in tqdm.tqdm(self.models):\n",
    "            pred = model.predict(test_x)\n",
    "            preds.append(pred)\n",
    "        preds = np.mean(preds, axis=0)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_keras(trial):   \n",
    "    optuna_MLP = KFoldsAverageMLP(FOLDS = 5)\n",
    "    optuna_MLP.fit(trial = trial, train_x = encoded_X_train, train_y = Y_train, prune = True)\n",
    "    return optuna_MLP.rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-18 21:37:20,412]\u001b[0m A new study created in memory with name: no-name-2af4b53a-b32a-48f6-8942-5d2829fc04bb\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "7500/7500 [==============================] - 164s 22ms/step - loss: 555.7933 - root_mean_squared_error: 17.9228 - val_loss: 0.7850 - val_root_mean_squared_error: 0.8860\n",
      "Epoch 2/1000\n",
      "7500/7500 [==============================] - 158s 21ms/step - loss: 0.9239 - root_mean_squared_error: 0.9610 - val_loss: 0.7904 - val_root_mean_squared_error: 0.8891\n",
      "Epoch 3/1000\n",
      "7500/7500 [==============================] - 153s 20ms/step - loss: 0.7942 - root_mean_squared_error: 0.8912 - val_loss: 0.7839 - val_root_mean_squared_error: 0.8854\n",
      "Epoch 4/1000\n",
      "7500/7500 [==============================] - 153s 20ms/step - loss: 0.7886 - root_mean_squared_error: 0.8880 - val_loss: 0.7842 - val_root_mean_squared_error: 0.8855\n",
      "Epoch 5/1000\n",
      "7500/7500 [==============================] - 153s 20ms/step - loss: 0.7923 - root_mean_squared_error: 0.8901 - val_loss: 0.7843 - val_root_mean_squared_error: 0.8856\n",
      "Epoch 6/1000\n",
      "7500/7500 [==============================] - 157s 21ms/step - loss: 0.7881 - root_mean_squared_error: 0.8877 - val_loss: 0.7857 - val_root_mean_squared_error: 0.8864\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 7/1000\n",
      "7500/7500 [==============================] - 157s 21ms/step - loss: 0.7868 - root_mean_squared_error: 0.8870 - val_loss: 0.7840 - val_root_mean_squared_error: 0.8854\n",
      "Epoch 8/1000\n",
      "7500/7500 [==============================] - 160s 21ms/step - loss: 0.7896 - root_mean_squared_error: 0.8886 - val_loss: 0.7839 - val_root_mean_squared_error: 0.8854\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/1000\n",
      "7500/7500 [==============================] - 163s 22ms/step - loss: 0.7869 - root_mean_squared_error: 0.8871 - val_loss: 0.7892 - val_root_mean_squared_error: 0.8884\n",
      "Epoch 2/1000\n",
      "7500/7500 [==============================] - 161s 21ms/step - loss: 0.7869 - root_mean_squared_error: 0.8871 - val_loss: 0.7891 - val_root_mean_squared_error: 0.8883\n",
      "Epoch 3/1000\n",
      "7500/7500 [==============================] - 162s 22ms/step - loss: 0.7869 - root_mean_squared_error: 0.8871 - val_loss: 0.7892 - val_root_mean_squared_error: 0.8884\n",
      "Epoch 4/1000\n",
      "2928/7500 [==========>...................] - ETA: 1:33 - loss: 0.7857 - root_mean_squared_error: 0.8864"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-dd319833e80e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlp_study\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimize\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpruner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHyperbandPruner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmlp_study\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb_study\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m         )\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             )\n\u001b[0;32m     72\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\optuna\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-5cc32aa5eaca>\u001b[0m in \u001b[0;36mobjective_keras\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mobjective_keras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0moptuna_MLP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFoldsAverageMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFOLDS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0moptuna_MLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprune\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moptuna_MLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-399423fd83e2>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, trial, train_x, train_y, prune)\u001b[0m\n\u001b[0;32m     88\u001b[0m                       \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_val_CV0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_CV1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_CV2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mY_val_CV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                       callbacks = [early_stop,\n\u001b[1;32m---> 90\u001b[1;33m                                     reduce_lr])       \n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_study = optuna.create_study(direction=\"minimize\", pruner = optuna.pruners.HyperbandPruner())\n",
    "mlp_study.optimize(objective_keras, n_trials=50)\n",
    "print(cb_study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
