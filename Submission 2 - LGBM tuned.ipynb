{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission 2: LGBM (tuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fundamentals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "# data exploration \n",
    "from pandas_profiling import ProfileReport\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=True, world_readable=True)\n",
    "from plotly.offline import iplot\n",
    "\n",
    "# data preprocessing \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, PowerTransformer, MinMaxScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# regressors\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "\n",
    "import xgboost as xgb \n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# metrics for evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "# saving parameters\n",
    "from joblib import dump, load\n",
    "\n",
    "# hyperparameter searching and tuning \n",
    "import optuna\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing random seed for reproducability\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('train.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = ['cat0','cat1','cat2','cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = original_df.drop(columns = 'target', axis =1)\n",
    "Y_train = original_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281421</td>\n",
       "      <td>0.881122</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.741413</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>0.724417</td>\n",
       "      <td>0.701915</td>\n",
       "      <td>0.877618</td>\n",
       "      <td>0.719903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.278495</td>\n",
       "      <td>0.593413</td>\n",
       "      <td>0.546056</td>\n",
       "      <td>0.613252</td>\n",
       "      <td>0.741289</td>\n",
       "      <td>0.326679</td>\n",
       "      <td>0.808464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293756</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.369602</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.865620</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.264104</td>\n",
       "      <td>0.695561</td>\n",
       "      <td>0.869133</td>\n",
       "      <td>0.828352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>K</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.934138</td>\n",
       "      <td>0.578930</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.868099</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>0.494269</td>\n",
       "      <td>0.698125</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.614766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279105</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.705940</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.462146</td>\n",
       "      <td>0.724447</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.343457</td>\n",
       "      <td>0.297743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont4     cont5  \\\n",
       "id                                                    ...                       \n",
       "1     A    B    A    A    B    D    A    E    C    I  ...  0.281421  0.881122   \n",
       "2     B    A    A    A    B    B    A    E    A    F  ...  0.282354  0.440011   \n",
       "3     A    A    A    C    B    D    A    B    C    N  ...  0.293756  0.914155   \n",
       "4     A    A    A    C    B    D    A    E    G    K  ...  0.769785  0.934138   \n",
       "6     A    B    A    A    B    B    A    E    C    F  ...  0.279105  0.382600   \n",
       "\n",
       "       cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
       "id                                                                         \n",
       "1   0.421650  0.741413  0.895799  0.802461  0.724417  0.701915  0.877618   \n",
       "2   0.346230  0.278495  0.593413  0.546056  0.613252  0.741289  0.326679   \n",
       "3   0.369602  0.832564  0.865620  0.825251  0.264104  0.695561  0.869133   \n",
       "4   0.578930  0.407313  0.868099  0.794402  0.494269  0.698125  0.809799   \n",
       "6   0.705940  0.325193  0.440967  0.462146  0.724447  0.683073  0.343457   \n",
       "\n",
       "      cont13  \n",
       "id            \n",
       "1   0.719903  \n",
       "2   0.808464  \n",
       "3   0.828352  \n",
       "4   0.614766  \n",
       "6   0.297743  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
       "       'cat9', 'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6',\n",
       "       'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
       "       'cat9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
    "       'cat9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in X_train.columns[0:10]:\n",
    "    X_train[feature] = X_train[feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = OrdinalEncoder()\n",
    "X_train[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
    "'cat9']] = le.fit_transform(X_train[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
    "'cat9']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281421</td>\n",
       "      <td>0.881122</td>\n",
       "      <td>0.421650</td>\n",
       "      <td>0.741413</td>\n",
       "      <td>0.895799</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>0.724417</td>\n",
       "      <td>0.701915</td>\n",
       "      <td>0.877618</td>\n",
       "      <td>0.719903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>0.440011</td>\n",
       "      <td>0.346230</td>\n",
       "      <td>0.278495</td>\n",
       "      <td>0.593413</td>\n",
       "      <td>0.546056</td>\n",
       "      <td>0.613252</td>\n",
       "      <td>0.741289</td>\n",
       "      <td>0.326679</td>\n",
       "      <td>0.808464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293756</td>\n",
       "      <td>0.914155</td>\n",
       "      <td>0.369602</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.865620</td>\n",
       "      <td>0.825251</td>\n",
       "      <td>0.264104</td>\n",
       "      <td>0.695561</td>\n",
       "      <td>0.869133</td>\n",
       "      <td>0.828352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769785</td>\n",
       "      <td>0.934138</td>\n",
       "      <td>0.578930</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.868099</td>\n",
       "      <td>0.794402</td>\n",
       "      <td>0.494269</td>\n",
       "      <td>0.698125</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.614766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279105</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.705940</td>\n",
       "      <td>0.325193</td>\n",
       "      <td>0.440967</td>\n",
       "      <td>0.462146</td>\n",
       "      <td>0.724447</td>\n",
       "      <td>0.683073</td>\n",
       "      <td>0.343457</td>\n",
       "      <td>0.297743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768447</td>\n",
       "      <td>0.269578</td>\n",
       "      <td>0.258655</td>\n",
       "      <td>0.363598</td>\n",
       "      <td>0.300619</td>\n",
       "      <td>0.340516</td>\n",
       "      <td>0.235711</td>\n",
       "      <td>0.383477</td>\n",
       "      <td>0.215227</td>\n",
       "      <td>0.793630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775951</td>\n",
       "      <td>0.197211</td>\n",
       "      <td>0.257024</td>\n",
       "      <td>0.574304</td>\n",
       "      <td>0.227035</td>\n",
       "      <td>0.322583</td>\n",
       "      <td>0.286094</td>\n",
       "      <td>0.324874</td>\n",
       "      <td>0.306933</td>\n",
       "      <td>0.230902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297406</td>\n",
       "      <td>0.449482</td>\n",
       "      <td>0.386172</td>\n",
       "      <td>0.476217</td>\n",
       "      <td>0.135947</td>\n",
       "      <td>0.502730</td>\n",
       "      <td>0.235788</td>\n",
       "      <td>0.316671</td>\n",
       "      <td>0.250286</td>\n",
       "      <td>0.349041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758642</td>\n",
       "      <td>0.363130</td>\n",
       "      <td>0.324132</td>\n",
       "      <td>0.229017</td>\n",
       "      <td>0.220888</td>\n",
       "      <td>0.515304</td>\n",
       "      <td>0.389391</td>\n",
       "      <td>0.245234</td>\n",
       "      <td>0.303895</td>\n",
       "      <td>0.481138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696047</td>\n",
       "      <td>0.734712</td>\n",
       "      <td>0.404145</td>\n",
       "      <td>0.497719</td>\n",
       "      <td>0.497974</td>\n",
       "      <td>0.782585</td>\n",
       "      <td>0.751251</td>\n",
       "      <td>0.608412</td>\n",
       "      <td>0.712868</td>\n",
       "      <td>0.452400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat0  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  ...  \\\n",
       "id                                                                  ...   \n",
       "1        0.0   1.0   0.0   0.0   1.0   3.0   0.0   4.0   2.0   8.0  ...   \n",
       "2        1.0   0.0   0.0   0.0   1.0   1.0   0.0   4.0   0.0   5.0  ...   \n",
       "3        0.0   0.0   0.0   2.0   1.0   3.0   0.0   1.0   2.0  13.0  ...   \n",
       "4        0.0   0.0   0.0   2.0   1.0   3.0   0.0   4.0   6.0  10.0  ...   \n",
       "6        0.0   1.0   0.0   0.0   1.0   1.0   0.0   4.0   2.0   5.0  ...   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "499993   0.0   1.0   0.0   2.0   1.0   1.0   0.0   4.0   4.0  11.0  ...   \n",
       "499996   0.0   1.0   0.0   2.0   1.0   1.0   0.0   4.0   4.0  11.0  ...   \n",
       "499997   0.0   1.0   0.0   2.0   1.0   1.0   0.0   4.0   2.0  12.0  ...   \n",
       "499998   0.0   1.0   1.0   2.0   1.0   1.0   0.0   3.0   4.0   5.0  ...   \n",
       "499999   0.0   0.0   1.0   0.0   1.0   3.0   0.0   4.0   2.0  10.0  ...   \n",
       "\n",
       "           cont4     cont5     cont6     cont7     cont8     cont9    cont10  \\\n",
       "id                                                                             \n",
       "1       0.281421  0.881122  0.421650  0.741413  0.895799  0.802461  0.724417   \n",
       "2       0.282354  0.440011  0.346230  0.278495  0.593413  0.546056  0.613252   \n",
       "3       0.293756  0.914155  0.369602  0.832564  0.865620  0.825251  0.264104   \n",
       "4       0.769785  0.934138  0.578930  0.407313  0.868099  0.794402  0.494269   \n",
       "6       0.279105  0.382600  0.705940  0.325193  0.440967  0.462146  0.724447   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "499993  0.768447  0.269578  0.258655  0.363598  0.300619  0.340516  0.235711   \n",
       "499996  0.775951  0.197211  0.257024  0.574304  0.227035  0.322583  0.286094   \n",
       "499997  0.297406  0.449482  0.386172  0.476217  0.135947  0.502730  0.235788   \n",
       "499998  0.758642  0.363130  0.324132  0.229017  0.220888  0.515304  0.389391   \n",
       "499999  0.696047  0.734712  0.404145  0.497719  0.497974  0.782585  0.751251   \n",
       "\n",
       "          cont11    cont12    cont13  \n",
       "id                                    \n",
       "1       0.701915  0.877618  0.719903  \n",
       "2       0.741289  0.326679  0.808464  \n",
       "3       0.695561  0.869133  0.828352  \n",
       "4       0.698125  0.809799  0.614766  \n",
       "6       0.683073  0.343457  0.297743  \n",
       "...          ...       ...       ...  \n",
       "499993  0.383477  0.215227  0.793630  \n",
       "499996  0.324874  0.306933  0.230902  \n",
       "499997  0.316671  0.250286  0.349041  \n",
       "499998  0.245234  0.303895  0.481138  \n",
       "499999  0.608412  0.712868  0.452400  \n",
       "\n",
       "[300000 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 1 to 499999\n",
      "Data columns (total 24 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   cat0    300000 non-null  float64\n",
      " 1   cat1    300000 non-null  float64\n",
      " 2   cat2    300000 non-null  float64\n",
      " 3   cat3    300000 non-null  float64\n",
      " 4   cat4    300000 non-null  float64\n",
      " 5   cat5    300000 non-null  float64\n",
      " 6   cat6    300000 non-null  float64\n",
      " 7   cat7    300000 non-null  float64\n",
      " 8   cat8    300000 non-null  float64\n",
      " 9   cat9    300000 non-null  float64\n",
      " 10  cont0   300000 non-null  float64\n",
      " 11  cont1   300000 non-null  float64\n",
      " 12  cont2   300000 non-null  float64\n",
      " 13  cont3   300000 non-null  float64\n",
      " 14  cont4   300000 non-null  float64\n",
      " 15  cont5   300000 non-null  float64\n",
      " 16  cont6   300000 non-null  float64\n",
      " 17  cont7   300000 non-null  float64\n",
      " 18  cont8   300000 non-null  float64\n",
      " 19  cont9   300000 non-null  float64\n",
      " 20  cont10  300000 non-null  float64\n",
      " 21  cont11  300000 non-null  float64\n",
      " 22  cont12  300000 non-null  float64\n",
      " 23  cont13  300000 non-null  float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 57.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in X_train.columns[0:10]:\n",
    "        X_train[feature] = X_train[feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 1 to 499999\n",
      "Data columns (total 24 columns):\n",
      " #   Column  Non-Null Count   Dtype   \n",
      "---  ------  --------------   -----   \n",
      " 0   cat0    300000 non-null  category\n",
      " 1   cat1    300000 non-null  category\n",
      " 2   cat2    300000 non-null  category\n",
      " 3   cat3    300000 non-null  category\n",
      " 4   cat4    300000 non-null  category\n",
      " 5   cat5    300000 non-null  category\n",
      " 6   cat6    300000 non-null  category\n",
      " 7   cat7    300000 non-null  category\n",
      " 8   cat8    300000 non-null  category\n",
      " 9   cat9    300000 non-null  category\n",
      " 10  cont0   300000 non-null  float64 \n",
      " 11  cont1   300000 non-null  float64 \n",
      " 12  cont2   300000 non-null  float64 \n",
      " 13  cont3   300000 non-null  float64 \n",
      " 14  cont4   300000 non-null  float64 \n",
      " 15  cont5   300000 non-null  float64 \n",
      " 16  cont6   300000 non-null  float64 \n",
      " 17  cont7   300000 non-null  float64 \n",
      " 18  cont8   300000 non-null  float64 \n",
      " 19  cont9   300000 non-null  float64 \n",
      " 20  cont10  300000 non-null  float64 \n",
      " 21  cont11  300000 non-null  float64 \n",
      " 22  cont12  300000 non-null  float64 \n",
      " 23  cont13  300000 non-null  float64 \n",
      "dtypes: category(10), float64(14)\n",
      "memory usage: 37.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat0',\n",
       " 'cat1',\n",
       " 'cat2',\n",
       " 'cat3',\n",
       " 'cat4',\n",
       " 'cat5',\n",
       " 'cat6',\n",
       " 'cat7',\n",
       " 'cat8',\n",
       " 'cat9']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldsAverageLGBM():\n",
    "    def __init__(self, FOLDS):\n",
    "        self.models = []\n",
    "        self.kfolds = KFold(n_splits = FOLDS, shuffle = False)\n",
    "            \n",
    "        \n",
    "    def fit(self, train_x, train_y, params, prune = True):\n",
    "        oof_preds = np.zeros_like(train_y)\n",
    "        self.train_x = train_x.values\n",
    "        self.train_y = train_y.values\n",
    "        \n",
    "        for train_idx, val_idx in self.kfolds.split(train_x):\n",
    "            X_train_CV, X_val_CV = self.train_x[train_idx], self.train_x[val_idx]\n",
    "            Y_train_CV, Y_val_CV = self.train_y[train_idx], self.train_y[val_idx]\n",
    "            \n",
    "            d_train = lgb.Dataset(data = X_train_CV, label=Y_train_CV)\n",
    "            d_val = lgb.Dataset(X_val_CV, label=Y_val_CV)\n",
    "            watchlist = [d_train, d_val]\n",
    "\n",
    "            # Add a callback for pruning.\n",
    "            pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"rmse\")\n",
    "            \n",
    "            # pruning for hyperparameter search, otherwise fit to params\n",
    "            if prune:\n",
    "                model = lgb.train(params, \n",
    "                                train_set = d_train,\n",
    "                                valid_sets = d_val,\n",
    "                                verbose_eval = -1,\n",
    "                                valid_names = 'valid_0',\n",
    "                                early_stopping_rounds = 1000,\n",
    "                                callbacks = [pruning_callback])\n",
    "            else:\n",
    "                model = lgb.train(params, \n",
    "                                 train_set = d_train,\n",
    "                                 valid_sets = d_val,\n",
    "                                 verbose_eval = -1,\n",
    "                                 valid_names = 'valid_0',\n",
    "                                 early_stopping_rounds = 1000)       \n",
    "        \n",
    "            self.models.append(model)\n",
    "            oof_pred = model.predict(X_val_CV)\n",
    "            oof_preds[val_idx] = oof_pred\n",
    "            \n",
    "        self.oof_preds = oof_preds\n",
    "        \n",
    "        self.rmse = mean_squared_error(Y_train, oof_preds, squared = False)\n",
    "\n",
    "    def predict(self, test_x):\n",
    "        preds = []\n",
    "        for model in tqdm.tqdm(self.models):\n",
    "            pred = model.predict(test_x)\n",
    "            preds.append(pred)\n",
    "        preds = np.mean(preds, axis=0)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_LGBM(trial):\n",
    "    num_leaves =  trial.suggest_int('num_leaves', 8, 4056, log=True) \n",
    "    lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-10, 1)\n",
    "    lambda_l2 = trial.suggest_loguniform('lambda_l2',1e-10, 1)\n",
    "    subsample_for_bin = trial.suggest_int('subsample_for_bin',1000, 1996000, step = 5000)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 1, 40, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 124, log=True)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction', 0, 1, step = 0.00001)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction', 0, 1, step = 0.00001)\n",
    "    bagging_freq = trial.suggest_int('bagging_freq', 1,10, step = 1)\n",
    "    max_bin = trial.suggest_int('max_bin', 2,256, log=True)\n",
    "    cat_l2 = trial.suggest_float('cat_l2', 0, 100, step = 0.1)\n",
    "    cat_smooth = trial.suggest_float('cat_smooth', 0, 100, step = 0.1)\n",
    "    \n",
    "    \n",
    "    objective_params =  {\n",
    "        'random_state' : 50,\n",
    "        'objective': 'rmse',\n",
    "        'learning_rate' : 0.00115,\n",
    "        'n_jobs' : -1,\n",
    "        'n_estimators' : 1000000, \n",
    "        'boosting_type' : 'gbdt',\n",
    "        \n",
    "        'num_leaves' :  num_leaves,\n",
    "        'lambda_l1' : lambda_l1,\n",
    "        'lambda_l2' : lambda_l2,\n",
    "        'subsample_for_bin' : subsample_for_bin,\n",
    "        'min_child_samples' : min_child_samples,\n",
    "        'max_depth' : max_depth,\n",
    "        'bagging_fraction': bagging_fraction,\n",
    "        'feature_fraction' : feature_fraction,\n",
    "        'bagging_freq' : bagging_freq,\n",
    "        'max_bin' : max_bin,\n",
    "        'cat_l2' : cat_l2,\n",
    "        'cat_smooth' : cat_smooth\n",
    "        }\n",
    "\n",
    "    \n",
    "    optuna_LGBM = KFoldsAverageLGBMTuning()\n",
    "    optuna_LGBM.fit(trial = trial, train_x = X_train, train_y = Y_train, params = objective_params)\n",
    "\n",
    "    return optuna_LGBM.rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning:\n",
      "\n",
      "Found `n_estimators` in params. Will use it instead of argument\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3625\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.456728\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18392]\tvalid_0's rmse: 0.837937\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3625\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.456104\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15948]\tvalid_0's rmse: 0.845988\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3625\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.456556\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21230]\tvalid_0's rmse: 0.841097\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3626\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.455560\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18576]\tvalid_0's rmse: 0.841278\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3626\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.456137\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17777]\tvalid_0's rmse: 0.842298\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3626\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.456299\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17242]\tvalid_0's rmse: 0.844323\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3625\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.457179\n",
      "Training until validation scores don't improve for 1000 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18076]\tvalid_0's rmse: 0.846605\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3626\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.455675\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17831]\tvalid_0's rmse: 0.838639\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3626\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.455984\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20656]\tvalid_0's rmse: 0.84059\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3626\n",
      "[LightGBM] [Info] Number of data points in the train set: 270000, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 7.456383\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21095]\tvalid_0's rmse: 0.840353\n",
      "0.841915171518219\n"
     ]
    }
   ],
   "source": [
    "tuned_LGBM = KFoldsAverageLGBM(FOLDS = 10)\n",
    "\n",
    "# from shogosuzuki & hamza\n",
    "kaggle_params = {'bagging_freq': 1, \n",
    "                 'reg_alpha': 2.4766410381355457, \n",
    "                 'reg_lambda': 2.644144282261626, \n",
    "                 'colsample_bytree': 0.3, \n",
    "                 'subsample': 0.6, \n",
    "                 'learning_rate': 0.001, \n",
    "                 'max_depth': 20, \n",
    "                 'num_leaves': 139, \n",
    "                 'min_child_samples': 176, \n",
    "                 'min_data_per_group': 9,\n",
    "                 'n_jobs' : -1,\n",
    "                 'objective': 'rmse',\n",
    "                 'n_estimators' : 1000000}\n",
    "\n",
    "\n",
    "\n",
    "tuned_LGBM.fit(train_x = X_train, train_y = Y_train, params = kaggle_params)\n",
    "print(tuned_LGBM.rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tuned_LGBM, 'submission2_tuned_LGBM.joblib', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = OrdinalEncoder()\n",
    "test[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
    "   'cat9']] = le.fit_transform(test[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8',\n",
    "   'cat9']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in test.columns[0:10]:\n",
    "    test[feature] = test[feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 = pd.read_csv('sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499987</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 5, 15, 16, 17, 19, 20, 21, 23, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 44, 49, 53, 56, 60, 61, 63, 64, 66, 70, 71, 72, 75, 76, 78, 85, 86, 89, 90, 92, 93, 94, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 116, 117, 118, 120, 129, 130, 132, 133, 134, 136, 137, 141, 142, 152, 154, 156, 160, 161, 166, 170, 173, 174, 175, 179, 182, 186, 188, 189, 191, 193, 194, 195, 196, 197, 199, 200, 202, 203, 204, 206, 207, 212, 217, 218, 220, 224, 225, 229, 230, ...]\n",
       "\n",
       "[200000 rows x 0 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workings = pd.DataFrame(index = test.index)\n",
    "workings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [31:09<00:00, 186.97s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499987</th>\n",
       "      <td>7.498402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>7.231649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>7.528269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>7.494877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>7.311966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lgbm\n",
       "id              \n",
       "499987  7.498402\n",
       "499990  7.231649\n",
       "499991  7.528269\n",
       "499994  7.494877\n",
       "499995  7.311966"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workings['lgbm'] = tuned_LGBM.predict(test)\n",
    "workings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2['target'] = workings['lgbm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2.to_csv('submission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
